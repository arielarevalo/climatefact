\section{Estado del arte}

En años recientes, la inteligencia artificial se ha consolidado como un área clave en el desarrollo tecnológico, dando lugar a un incremento significativo en las investigaciones vinculadas a sus múltiples aplicaciones. Este auge se explica por la capacidad de la IA para ofrecer respuestas innovadoras y eficaces a problemas complejos en distintos sectores, entre ellos la educación, el entorno empresarial, la salud y el medio ambiente. Bajo esta perspectiva, el presente estado del arte explora los principales avances científicos en el uso de la inteligencia artificial para tareas como el procesamiento del lenguaje natural, la verificación automática de datos y la creación de modelos lingüísticos de gran escala.

Primero tenemos el trabajo realizado por Chavarría Muñoz~\cite{chavarria2022}, quien desarrolló un prototipo de aplicación web para la detección de noticias falsas en español, integrando algoritmos de clasificación como \textit{Support Vector Machine}, \textit{Random Forest} y \textit{Passive Aggressive Classifier}, junto con técnicas de procesamiento de lenguaje natural como análisis de sentimiento, modelado de temas y detección de lenguaje soez. El estudio utilizó un corpus balanceado de 1248 noticias (mitad falsas y mitad verdaderas), alcanzando niveles de precisión cercanos al 72\% con el clasificador \textit{Random Forest}. A través del uso de herramientas como Python, Streamlit y Heroku, el prototipo permitió que los usuarios ingresaran el título y cuerpo de una noticia, recibiendo como resultado un porcentaje estimado de veracidad junto con métricas lingüísticas asociadas, lo que representa un aporte relevante en la automatización del análisis crítico de contenido digital en español~\cite{chavarria2022}.

Luego tenemos el trabajo de Rey Morales~\cite{rey2025fakenews}, quien desarrolló un modelo para la detección de noticias falsas combinando diversas técnicas de procesamiento de lenguaje natural y algoritmos de clasificación. En su estudio se implementaron enfoques como TF-IDF, Bag of Words, Word2Vec y el modelo transformer DistilBERT, junto con clasificadores como regresión logística, Support Vector Machines y Random Forest. Además, aplicó técnicas como reducción de dimensionalidad con PCA y validación cruzada para mejorar la precisión. Una de las principales conclusiones fue que, si bien los modelos avanzados como BERT lograron altos niveles de precisión (superiores al 99\%), el análisis contextual de elementos externos a la noticia ---como comentarios, fuente y similitud con otras noticias--- es esencial para alcanzar predicciones más fiables. Este trabajo contribuye al estado del arte al ofrecer una comparación exhaustiva de métodos y evidenciar la importancia del contexto en la detección automatizada de desinformación.

Por ultimo tenemos el trabajo desarrollado por Mafla Checa~\cite{mafla2021noticias}, titulado \textit{``Identificación automática de noticias falsas en español utilizando técnicas de minería de datos y procesamiento de lenguaje natural''}. Este estudio lo que propone es una metodología completa que abarca desde la construcción de un corpus de noticias ecuatorianas hasta la implementación y comparación de modelos de clasificación supervisada. El autor recopila manualmente un conjunto de noticias reales y falsas provenientes de medios nacionales y páginas de política, y posteriormente aplica técnicas de \textit{procesamiento de lenguaje natural (PLN)} como la lematización, remoción de \textit{stop words} y representación vectorial mediante \textit{TF-IDF}. Para abordar el desequilibrio en las clases, se emplea la técnica de sobremuestreo \textit{SMOTE}. El estudio evalúa el desempeño de diferentes modelos de clasificación, incluyendo \textit{Support Vector Machines (SVM)}, \textit{Naive Bayes}, \textit{Random Forest} y \textit{Boosting}, utilizando métricas como la precisión, \textit{F1-score} y curvas \textit{ROC}. Los resultados mostraron que los modelos más eficientes fueron SVM y Boosting, con un rendimiento considerablemente superior cuando se aplicó un preprocesamiento exhaustivo de los textos.
